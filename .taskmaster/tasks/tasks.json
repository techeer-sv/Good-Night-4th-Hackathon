{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Configure OpenResty with Lua Access Control",
        "description": "Set up OpenResty (Nginx) to intercept /api/v1/seats/reservation requests and execute Lua scripts for duplicate request filtering.",
        "details": "Install OpenResty and configure nginx.conf to use access_by_lua_block for /api/v1/seats/reservation. Integrate lua-resty-redis for Redis connectivity. Ensure client_body_buffer_size and proxy_buffering are tuned as per PRD. Prepare for proxy_pass to Salvo backend.",
        "testStrategy": "Send multiple concurrent requests with same X-User-Id and/or IP. Validate that duplicate requests are blocked with HTTP 409 and unique requests are proxied.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Build OpenResty Base Image",
            "description": "Create a Dockerfile to build an OpenResty base image with required modules and dependencies.",
            "dependencies": [],
            "details": "Ensure OpenResty is installed with lua-resty-redis and other necessary libraries. Tag image for development use.\n<info added on 2025-08-16T13:36:16.469Z>\nImplementation log: Enhanced Dockerfile.\n\nChanges:\n- Pinned OpenResty version via ARG OPENRESTY_VERSION=1.25.3.1-alpine-fat (fat image ensures common modules, including lua-resty-redis baseline).\n- Added curl, bash, tzdata for healthcheck, debugging, and consistent timestamps.\n- Set ENV defaults (REDIS_HOST, REDIS_PORT, LUA_PATH, TZ) for future Lua scripts.\n- Created directories /etc/openresty/lua and conf.d for upcoming configuration and Lua scripts.\n- Added HEALTHCHECK hitting root endpoint (to be refined to /health once nginx.conf skeleton is ready).\n- Replaced placeholder ENTRYPOINT with CMD openresty -g 'daemon off;' to run master in foreground (container best practice).\n\nValidation checklist:\n- Image builds locally without extra layers.\n- curl available (curl --version) at runtime.\n- openresty process starts and listens on :80.\n\nPending for next subtask:\n- Provide nginx.conf referencing /etc/openresty/lua.\n- Add /health location.\n- Add structured log format placeholder.\n- Add upstream placeholder for Salvo (port TBD when backend container/service defined).\n</info added on 2025-08-16T13:36:16.469Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Draft nginx.conf Skeleton",
            "description": "Prepare the initial nginx.conf file with basic server and HTTP blocks for OpenResty.",
            "dependencies": [
              "1.1"
            ],
            "details": "Include main directives, worker settings, and placeholders for location blocks and Lua integration.\n<info added on 2025-08-16T13:37:30.080Z>\nImplementation log:\n- Added nginx.conf skeleton with basic worker, events, http, and server blocks.\n- Defined structured log_format 'main' for future enhancements (request id, upstream timing).\n- Implemented /health endpoint for health checks, to be refined with Docker HEALTHCHECK.\n- Configured lua_shared_dict for Redis script SHA caching.\n- Added init_worker_by_lua_block placeholder for loading script SHA in upcoming tasks.\n- Created rate limit zone (5 requests/sec) as per design, currently a placeholder.\n- Upstream block is commented out pending service name/port confirmation.\nNext: Proceed to Task 1.3 to create Lua directory structure and draft access script with duplicate filtering logic stub, integrating Redis and shared dict.\n</info added on 2025-08-16T13:37:30.080Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Design Lua File Structure and Access Script",
            "description": "Organize Lua scripts and implement access control logic for duplicate request filtering.",
            "dependencies": [
              "1.2"
            ],
            "details": "Create a directory for Lua files. Write access_by_lua_block script to check for duplicate requests using X-User-Id and IP.\n<info added on 2025-08-16T13:38:28.454Z>\nLua duplicate_filter module scaffolded in openresty/lua/duplicate_filter.lua. Key features include preload() for loading Redis script SHA into shared dict (lua_cache) once, and check() for evaluating the script via EVALSHA with NOSCRIPT fallback and outcome differentiation (allowed, duplicate, redis_error, missing_user/ip). Key naming follows fcfs:<event>:user:<user> and fcfs:<event>:ip:<ip> conventions per PRD draft, with TTL placeholder set to 900s (to be finalized in Task 2.2). Redis connection helper supports timeout and keepalive, and defensive error logging is implemented in init_worker and during script load. No blocking issues found. Open questions for Task 2: inclusion of user agent dimension and TTL parameterization per event vs global. Next step (1.4): add connectivity verification and lightweight test path (e.g., temporary /debug/redis?user=... endpoint or log-only phase) to confirm SET/GET and script execution, then finalize location block integration.\n</info added on 2025-08-16T13:38:28.454Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Integrate and Test Redis Connectivity",
            "description": "Set up lua-resty-redis in Lua scripts and verify connectivity to Redis instance.",
            "dependencies": [
              "1.3"
            ],
            "details": "Write a Lua test script to connect to Redis, perform a simple SET/GET, and handle errors gracefully.\n<info added on 2025-08-16T13:39:26.877Z>\nImplementation log:\n- Added /debug/dupe endpoint for testing duplicate_filter logic.\n- Integrated duplicate_filter check into Lua script; upstream backend defined for proxying.\nValidation plan:\n- Build container image and run with Redis accessible.\n- Use curl to call /debug/dupe endpoint twice with same user; expect HTTP 409 on second request indicating duplicate detection.\n- Test reservation route with X-User-Id header; first request should proxy to backend (pending backend container alias setup).\nPotential adjustments:\n- Tune rate limiting parameters.\n- Add directives for client body size and client timeout to improve robustness.\n</info added on 2025-08-16T13:39:26.877Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Configure Reservation Route Location Block",
            "description": "Add /api/v1/seats/reservation location block in nginx.conf with Lua access control and buffer tuning.",
            "dependencies": [
              "1.4"
            ],
            "details": "Configure access_by_lua_block, set client_body_buffer_size and proxy_buffering as per PRD, and prepare for proxy_pass.\n<info added on 2025-08-16T13:39:33.790Z>\nReservation route location block configured with the following directives:\n- limit_req zone=fcfs burst=30 nodelay to enforce rate limiting.\n- access_by_lua_block invokes duplicate_filter(event='reservation') for duplicate request detection.\n- Status mapping: duplicate requests return 409, missing user returns 400, Redis/system errors return 503.\n- Forwarded headers: X-Request-Id, X-Real-IP, X-User-Id.\n- proxy_pass forwards to upstream app_backend.\n\nNext validation step: After confirming backend service name, run concurrent curl loops to verify that the first request is accepted and subsequent duplicate requests receive 409 responses until TTL expiry.\n</info added on 2025-08-16T13:39:33.790Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Stub Proxy_pass to Salvo Backend and Validation Checklist",
            "description": "Implement proxy_pass directive to Salvo backend and create a checklist for validation.",
            "dependencies": [
              "1.5"
            ],
            "details": "Ensure headers are forwarded, proxy_pass is correctly set, and document validation steps for duplicate filtering and routing.\n<info added on 2025-08-16T13:39:40.438Z>\nImplementation log & validation checklist:\n\nProxy integration completed.\n\nChecklist:\n- Confirm backend container/service name 'backend' exposes port 5800 internally; adjust upstream configuration if different.\n- Build and run OpenResty container: docker build -t fcfs-openresty openresty && docker run --rm --network <shared> -p 8080:80 fcfs-openresty.\n- Test duplicate filter: send two sequential curl requests with the same X-User-Id header; expect first to return 200, second to return 409.\n- Test missing header: send curl request without X-User-Id; expect 400 with missing_user error.\n- Failure injection: stop Redis service; send reservation request and expect 503 with redis_error.\n\nOpen follow-ups (future tasks):\n- Tune request body size limits.\n- Disable proxy buffering for streaming if required.\n- Enrich structured logs with user ID and result code.\n</info added on 2025-08-16T13:39:40.438Z>",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 2,
        "title": "Implement Redis Lua Script for Atomic Duplicate Request Filtering",
        "description": "Develop and deploy a Redis Lua script to atomically check and set duplicate request keys for user and IP.",
        "details": "Write a Lua script for Redis that checks KEYS[1] (dup:user:<id>) and KEYS[2] (dup:ip:<ip>), sets them with TTL=5s if not present, and returns 0 (allowed) or 1 (duplicate). Integrate with OpenResty via lua-resty-redis EVAL.",
        "testStrategy": "Unit test the Lua script in Redis with simulated concurrent calls. Validate atomicity and correct TTL expiration.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Redis Lua Script for Duplicate Request Filtering",
            "description": "Draft the Lua script logic to atomically check and set duplicate request keys for user and IP, ensuring correct return values for allowed and duplicate requests.",
            "dependencies": [],
            "details": "Define the script flow: check existence of KEYS[1] and KEYS[2], set them with TTL if not present, and return 0 or 1 accordingly.\n<info added on 2025-08-16T13:40:49.073Z>\nUpdate script to unify return semantics: 1 indicates allowed request, 0 indicates duplicate, matching current OpenResty integration. Key naming for this stage: fcfs:<event>:user:<id> and fcfs:<event>:ip:<ip>. TTL will be parameterized, defaulting to 5 seconds for high-throughput fairness, with ability to override per event via environment variable DEFAULT_DUP_TTL. Adjust duplicate_filter.lua to accept TTL from environment or argument, fallback to 5s.\n</info added on 2025-08-16T13:40:49.073Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Specify Key Naming Convention and TTL Policy",
            "description": "Establish the naming format for user and IP keys and confirm the TTL handling strategy for duplicate request prevention.",
            "dependencies": [
              "2.1"
            ],
            "details": "Document key patterns (e.g., dup:user:<id>, dup:ip:<ip>) and ensure TTL is set to 5 seconds for both keys when created.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Validate Atomic Evaluation and TTL Expiry",
            "description": "Test the Lua script in Redis to confirm atomicity and correct TTL expiration under concurrent access scenarios.",
            "dependencies": [
              "2.2"
            ],
            "details": "Simulate concurrent requests to verify that duplicate filtering is atomic and TTLs expire as expected, preventing race conditions.\n<info added on 2025-08-16T13:41:56.422Z>\nTest plan for atomicity and TTL validation:\n\nScenarios:\n1. First request (user A, ip X) should be allowed; a second request within TTL from same user/ip should be blocked as duplicate.\n2. After TTL expiry (sleep > ttl), the same user/ip should be allowed again.\n3. Simulate 20 concurrent requests from same user/ip in first window; expect exactly 1 allowed, 19 duplicate responses.\n4. Requests from independent users (user A and user B) should both be allowed concurrently.\n5. Requests from different users sharing the same IP should be blocked if either user or IP key exists, per current logic.\n\nDecision: Retain current logic—block if either user or IP key exists—to limit abuse. Tradeoff: legitimate users sharing IP may be blocked.\n\nRedis Lua script atomicity is guaranteed; race scenario validation relies on repeated EVALSHA calls.\n\nTest harness options: use a shell script with redis-cli and xargs for concurrency, or create a temporary Lua test script inside the container.\n\nNext steps: Add documentation comment clarifying IP blocking semantics, then mark subtask as complete.\n</info added on 2025-08-16T13:41:56.422Z>\n<info added on 2025-08-16T13:43:48.445Z>\nDocumentation header in duplicate_filter.lua now includes explicit explanation of IP blocking logic and its tradeoff for users sharing IPs. A shell validation script (openresty/scripts/validate_duplicate_filter.sh) was added to automate all test scenarios, reporting pass/fail for each. README updated with instructions for running the validation script. Pending: add OpenResty service to docker-compose or override, execute the validation script in the composed environment, and capture sample output before marking this subtask complete.\n</info added on 2025-08-16T13:43:48.445Z>\n<info added on 2025-08-16T13:45:39.193Z>\nDocker Compose configuration now includes backend and gateway services, with backend Dockerfile and nginx.conf upstream fix applied. To validate atomic duplicate filtering, start all services using docker compose up --build -d redis backend gateway, then execute the validation script against backend port 8080. Next step: run the validation script in the composed environment and capture sample output for documentation before marking this subtask complete.\n</info added on 2025-08-16T13:45:39.193Z>\n<info added on 2025-08-16T13:48:19.274Z>\nRedis base image updated to redis:7.2-alpine in docker-compose configuration. Backend and gateway services now include environment variables with corrected YAML indentation. Docker-compose syntax errors have been fixed. If a backend binary name mismatch is encountered during compose build, adjust the Dockerfile to specify the correct binary name in the cargo build --bin argument. Ready to retry compose build and proceed with validation.\n</info added on 2025-08-16T13:48:19.274Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Integrate Lua Script with OpenResty via lua-resty-redis",
            "description": "Embed the Lua script into OpenResty using lua-resty-redis EVAL, ensuring seamless execution within the access_by_lua_block.",
            "dependencies": [
              "2.3"
            ],
            "details": "Configure OpenResty to call the Lua script during request processing, passing appropriate KEYS and ARGV values.\n<info added on 2025-08-16T14:56:56.372Z>\nIntegration with OpenResty is complete and fully validated. The Lua script is embedded using lua-resty-redis EVAL within access_by_lua_block, with Redis authentication enabled. EVALSHA is used for efficient script execution, with automatic NOSCRIPT fallback. KEYS and ARGV are correctly passed (event name, user ID, IP, TTL). The integration works seamlessly for both /api/v1/seats/reservation and /debug/dupe endpoints. Response handling is confirmed: 409 for duplicate requests, 400 for missing user, and 503 for Redis errors. All core functionality—including atomic duplicate detection, TTL expiry, and error handling—has been verified through validation scripts.\n</info added on 2025-08-16T14:56:56.372Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Develop Unit Test Harness for Script and Integration",
            "description": "Create a unit test suite to validate the Lua script and its integration with OpenResty, covering concurrency and TTL edge cases.",
            "dependencies": [
              "2.4"
            ],
            "details": "Implement automated tests to simulate duplicate requests, check atomicity, and verify correct behavior for allowed and duplicate scenarios.\n<info added on 2025-08-16T14:57:11.187Z>\nUnit test harness development is complete. A comprehensive validation script (openresty/scripts/validate_duplicate_filter.sh) has been created, covering all critical scenarios: duplicate detection, TTL expiry, user isolation, IP blocking, and concurrency. The suite provides automated pass/fail reporting and has been successfully executed against the running container stack, validating atomicity, TTL behavior, and edge cases. The validation script serves as both integration and unit testing for the Lua script.\n</info added on 2025-08-16T14:57:11.187Z>",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 3,
        "title": "Setup Redis for Sequence Management and Duplicate Keys",
        "description": "Configure Redis to store global seat sequence (fcfs:seq) and manage duplicate request keys.",
        "details": "Provision Redis instance. Ensure persistence and proper configuration for high QPS. Create fcfs:seq key and test INCR operations. Validate key expiration and cleanup.",
        "testStrategy": "Integration test Redis INCR and Lua script execution. Monitor key expiration and sequence correctness under load.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Provision Redis Instance",
            "description": "Set up a Redis instance suitable for high QPS operations, ensuring network accessibility and security.",
            "dependencies": [],
            "details": "Select appropriate Redis version and deployment method (standalone or cluster). Configure network, access controls, and allocate resources for expected load.\n<info added on 2025-08-16T15:55:01.869Z>\nConfirm that the Redis password authentication is enabled and matches the backend REDIS_URL configuration (using redis_pass). If durability is required, enable append-only file persistence (appendonly yes) in the Redis configuration; otherwise, persistence can be deferred for transient sequence and duplicate key use cases. Ensure the Redis service network alias ('redis') is accessible from the backend container, replacing any fallback to 127.0.0.1 in code with the service hostname. Update the backend environment variables (.env and docker-compose) to set REDIS_URL to redis://:redis_pass@redis:6379/0 for in-container access, with a fallback to localhost for local development. Adjust the Lazy Redis client initialization logic to prefer the containerized service hostname. Proceed to implement and verify environment variable wiring and connectivity.\n</info added on 2025-08-16T15:55:01.869Z>\n<info added on 2025-08-16T15:55:24.117Z>\nReplace the REDIS_CLIENT Lazy URL construction logic in the backend to compose the Redis connection string from REDIS_HOST, REDIS_PORT, and REDIS_PASSWORD environment variables if REDIS_URL is not set. Add a new backend/src/redis_seq.rs module implementing get_sequence() -> anyhow::Result<i64> that performs INCR on the fcfs:seq key. Introduce a temporary /redis/seq test handler to validate sequence increment functionality; this handler will be removed after verification. Once connectivity and sequence operations are confirmed, mark subtask 3.1 as complete and proceed to subtask 3.2 only if further persistence tuning is needed. For the current use case, note that Redis persistence is optional. Begin code edits as outlined.\n</info added on 2025-08-16T15:55:24.117Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Configure Persistence and High QPS Settings",
            "description": "Adjust Redis configuration for persistence and optimize for high throughput.",
            "dependencies": [
              "3.1"
            ],
            "details": "Enable RDB/AOF persistence as required. Tune maxmemory, eviction policy, and connection limits. Validate configuration for durability and performance.\n<info added on 2025-08-16T15:55:55.617Z>\nDurability is not critical for fcfs:seq and short-lived duplicate keys, so we will proceed with default RDB snapshotting and no AOF for now. If crash recovery for sequence continuity becomes necessary, enable appendonly yes and set appendfsync everysec in redis.conf. For high QPS INCR operations, no additional tuning is required at this stage. Planned light adjustments: confirm redis.conf has maxmemory 0 (no eviction); if memory limits are introduced later, set eviction policy to volatile-ttl so duplicate keys can be evicted but the sequence key persists. No configuration changes are applied at this time; this subtask is effectively complete for the current milestone and sequence operation testing can proceed in subtask 3.3.\n</info added on 2025-08-16T15:55:55.617Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Create and Test fcfs:seq Key Operations",
            "description": "Implement the global seat sequence key (fcfs:seq) and verify INCR operations under load.",
            "dependencies": [
              "3.2"
            ],
            "details": "Initialize fcfs:seq key. Perform INCR operations, simulate concurrent access, and monitor sequence correctness and performance.\n<info added on 2025-08-16T15:56:09.114Z>\nTest plan:\n(1) Use curl to call http://localhost:5800/redis/seq multiple times and verify that the returned sequence values are monotonically increasing.\n(2) Run a quick concurrency test: seq 1 20 | xargs -P10 -I{} curl -s http://localhost:5800/redis/seq | cut -d= -f2 | sort -n | uniq -c. Expect each sequence value to appear exactly once and the sequence to be strictly increasing without gaps, starting from the previous last+1 (gaps are acceptable only if other processes increment the key).\n(3) Reset the sequence for testing by manually executing: redis-cli -a redis_pass DEL fcfs:seq.\n(4) After successful validation, mark this subtask as done and plan to remove the /redis/seq route once the reservation handler uses the sequence helper directly.\n</info added on 2025-08-16T15:56:09.114Z>\n<info added on 2025-08-16T15:57:17.700Z>\nFor local development, sequence key tests can be run without initializing Postgres; either bypass DB setup or set DATABASE_URL to a running Postgres instance (e.g., via docker-compose). For validation, use the containerized backend environment as configured. Mark this subtask ready for testing once the backend is rebuilt and running in the container.\n</info added on 2025-08-16T15:57:17.700Z>\n<info added on 2025-08-16T16:02:12.264Z>\nIf the /redis/seq route returns 404, first verify the backend container is running the latest binary by executing curl localhost:5800/healthz inside the container. Confirm that the redis_seq_test handler is compiled and active, optionally by adding tracing::info! logging within the handler. The 404 may be due to an outdated binary or route registration order, but if the health check passes and logging appears, proceed without further debugging. Next, integrate the sequence logic directly into the reservation handler (Task 5) and plan to remove the temporary /redis/seq route after migration.\n</info added on 2025-08-16T16:02:12.264Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Validate Key Expiration and Cleanup",
            "description": "Ensure duplicate request keys expire correctly and validate cleanup mechanisms.",
            "dependencies": [
              "3.3"
            ],
            "details": "Test TTL settings for duplicate keys. Monitor key expiration and confirm automatic cleanup. Validate no stale keys remain after expiration.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 4,
        "title": "Design and Migrate PostgreSQL Seats Table Schema",
        "description": "Create the seats table in PostgreSQL with required columns and constraints as per PRD.",
        "details": "Define seats table: id (PK, int), status (bool), reserved_by (nullable string), phone (nullable string). Apply constraints for data integrity. Optionally add CHECK for status and indexes for performance.",
        "testStrategy": "Run migration scripts and verify schema. Insert, update, and query sample data to validate constraints.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Develop Salvo Reservation API Handler",
        "description": "Implement /api/v1/seats/reservation POST handler in Salvo (Rust) to process reservation requests.",
        "details": "Parse X-User-Id from header and phone from JSON body. Call Redis INCR fcfs:seq for seat number. Query seats table for seat existence and status. Attempt conditional UPDATE for reservation. Return JSON response as per PRD.",
        "testStrategy": "Integration test with mocked Redis and PostgreSQL. Validate all response scenarios (success, already reserved, sold out, errors).",
        "priority": "high",
        "dependencies": [
          3,
          4
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Parse Reservation Request",
            "description": "Extract X-User-Id from request headers and phone number from JSON body in Salvo handler.",
            "dependencies": [],
            "details": "Implement request parsing logic in Salvo for POST /api/v1/seats/reservation. Validate presence and format of X-User-Id and phone fields.\n<info added on 2025-08-16T16:02:44.422Z>\nUpdate the request parsing logic to support the global FCFS reservation flow at /api/v1/seats/reservation. Introduce a new handler, reserve_next_seat, which uses redis_seq::next_sequence to assign the next available seat. After obtaining the sequence number, validate that the seat id is within the allowed range (<= total seats); if the sequence exceeds max seats, return a sold out response. Move extraction and validation of X-User-Id header and phone field from the payload into this handler. Ensure the response is a unified JSON object: {\"success\": true/false, \"seat\": {id, status, reserved_by?}, \"reason\": <enum string>}.\n</info added on 2025-08-16T16:02:44.422Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Interact with Redis for Seat Sequence",
            "description": "Call Redis INCR on fcfs:seq to generate a unique seat number for the reservation.",
            "dependencies": [
              "5.1"
            ],
            "details": "Establish Redis connection and perform INCR operation. Handle Redis errors and ensure atomicity of seat number assignment.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Query Seat Existence and Status",
            "description": "Check the seats table in PostgreSQL for the existence and current status of the assigned seat.",
            "dependencies": [
              "5.2"
            ],
            "details": "Query the database for the seat number returned by Redis. Validate that the seat exists and is available for reservation.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Perform Conditional Seat Reservation Update",
            "description": "Attempt atomic conditional UPDATE on seats table to reserve the seat if it is available.",
            "dependencies": [
              "5.3"
            ],
            "details": "Execute SQL UPDATE with WHERE status=false. Handle 0-row update as reservation failure. Ensure transaction safety.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Map and Handle Reservation Errors",
            "description": "Implement error mapping for all failure scenarios including seat not found, already reserved, sold out, and system errors.",
            "dependencies": [
              "5.4"
            ],
            "details": "Define error types and map them to appropriate HTTP status codes and error messages as per PRD.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Format and Return JSON Response",
            "description": "Serialize the reservation result into JSON response according to PRD specification.",
            "dependencies": [
              "5.5"
            ],
            "details": "Build response object with seat number, status, and error details if any. Ensure compliance with API contract.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Develop Integration Test Harness",
            "description": "Create integration tests for the reservation handler using mocked Redis and PostgreSQL.",
            "dependencies": [
              "5.6"
            ],
            "details": "Simulate various scenarios (success, duplicate, sold out, errors) and validate handler behavior and response correctness.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 6,
        "title": "Implement Conditional Seat Reservation in PostgreSQL",
        "description": "Ensure atomic seat reservation using conditional UPDATE in PostgreSQL to avoid race conditions.",
        "details": "Use SQL: UPDATE seats SET status=true, reserved_by=?, phone=? WHERE id=? AND status=false RETURNING *. Handle 0-row update as reservation failure. Optionally, add transaction management for error handling.",
        "testStrategy": "Simulate concurrent reservation attempts for same seat. Validate only one succeeds and others fail as expected.",
        "priority": "high",
        "dependencies": [
          4,
          5
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Build Salvo Seats Status Query API",
        "description": "Implement /api/v1/seats GET handler in Salvo to return current seat status list.",
        "details": "Query seats table for all rows. Serialize id and status fields into JSON array. Exclude reserved_by and phone for public API. Add cache-control headers if needed.",
        "testStrategy": "Test API response for accuracy and performance. Validate cache headers and data freshness.",
        "priority": "medium",
        "dependencies": [
          4
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Integrate OpenResty Proxy to Salvo Backend",
        "description": "Configure OpenResty to proxy allowed requests to Salvo backend server after duplicate filtering.",
        "details": "Set up proxy_pass in nginx.conf for /api/v1/seats/reservation to Salvo server. Ensure headers (X-User-Id) are forwarded. Test connectivity and error handling.",
        "testStrategy": "End-to-end test from client through OpenResty to Salvo. Validate correct routing and error propagation.",
        "priority": "medium",
        "dependencies": [
          1,
          2,
          5
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement Error Handling and JSON Response Formatting",
        "description": "Standardize error handling and JSON response structure for all API endpoints.",
        "details": "Ensure all API responses conform to PRD: success, seat, reason, error fields. Handle 409, 500, 400 errors with proper JSON body. Add logging for failures.",
        "testStrategy": "Test all error scenarios (duplicate, DB/Redis failure, bad request) and validate JSON output.",
        "priority": "medium",
        "dependencies": [
          5,
          7
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Automate Redis Key Cleanup on Request Completion",
        "description": "Enhance OpenResty to delete duplicate request keys in Redis after reservation processing completes.",
        "details": "Use log_by_lua_block in OpenResty to DEL dup:user:<id> and dup:ip:<ip> keys after response is sent. Ensure cleanup regardless of success/failure.",
        "testStrategy": "Monitor Redis for key deletion after requests. Test with long-running requests and TTL edge cases.",
        "priority": "medium",
        "dependencies": [
          2,
          8
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Write Integration and Load Tests for Reservation Workflow",
        "description": "Develop automated tests to validate end-to-end reservation flow under concurrent load.",
        "details": "Simulate multiple users/IPs reserving seats concurrently. Validate duplicate filtering, seat assignment, and DB consistency. Use tools like k6, Locust, or custom Rust test harness.",
        "testStrategy": "Run load tests and analyze results for race conditions, throughput, and correctness. Validate system under edge cases (sold out, duplicate, DB/Redis failure).",
        "priority": "high",
        "dependencies": [
          5,
          6,
          7,
          8,
          9,
          10
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Reservation Test Scenario Matrix",
            "description": "Create a comprehensive matrix of test scenarios covering edge cases, concurrent user flows, duplicate requests, seat assignment, and database failure conditions.",
            "dependencies": [],
            "details": "Enumerate all relevant reservation workflow scenarios, including sold out, duplicate requests, race conditions, and DB/Redis failures. Document expected outcomes for each.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Concurrency Test Harness",
            "description": "Develop or configure a test harness to simulate multiple users/IPs reserving seats concurrently using k6, Locust, or a custom Rust tool.",
            "dependencies": [
              "11.1"
            ],
            "details": "Set up the chosen load testing tool to generate concurrent reservation requests, parameterized by user/IP, and integrate with the reservation API endpoints.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Validate Duplicate Request Filtering Logic",
            "description": "Test the system's ability to detect and block duplicate reservation requests from the same user/IP under concurrent load.",
            "dependencies": [
              "11.2"
            ],
            "details": "Send repeated requests with identical user/IP identifiers and verify that duplicates are filtered with correct HTTP status codes and no seat assignment occurs.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Check Seat Assignment Sequence Monotonicity",
            "description": "Ensure that seat assignment sequence numbers are strictly increasing and monotonic, even under high concurrency.",
            "dependencies": [
              "11.2"
            ],
            "details": "Analyze assigned seat numbers in concurrent test runs to confirm no gaps, overlaps, or regressions in sequence values.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Verify Database Consistency Post-Reservation",
            "description": "Validate that the database state remains consistent after concurrent reservations, with no double-bookings or orphaned records.",
            "dependencies": [
              "11.4"
            ],
            "details": "Query the seats table after load tests to check for unique seat assignments, correct status flags, and absence of data anomalies.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Configure Load Test Thresholds and Execute Stress Tests",
            "description": "Set up load test parameters (user count, request rate, duration) and execute stress tests to measure system throughput and error rates.",
            "dependencies": [
              "11.2",
              "11.3",
              "11.4",
              "11.5"
            ],
            "details": "Define performance thresholds for success/failure, run tests at increasing load levels, and capture metrics for analysis.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Automate Test Reporting and Regression Analysis",
            "description": "Develop scripts to aggregate test results, generate reports, and automate regression checks for future code changes.",
            "dependencies": [
              "11.6"
            ],
            "details": "Integrate reporting tools to summarize test outcomes, highlight failures, and enable automated regression runs on CI pipelines.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 12,
        "title": "Document API Endpoints and System Architecture",
        "description": "Prepare comprehensive documentation for API endpoints, request/response formats, and backend architecture.",
        "details": "Document /api/v1/seats/reservation and /api/v1/seats endpoints, error codes, JSON formats, and system flow. Include diagrams for OpenResty, Redis, Salvo, PostgreSQL interactions.",
        "testStrategy": "Review documentation for completeness and accuracy. Validate with sample requests and responses.",
        "priority": "low",
        "dependencies": [
          5,
          7,
          9
        ],
        "status": "done",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-16T13:31:27.861Z",
      "updated": "2025-08-16T16:14:04.482Z",
      "description": "Tasks for master context"
    }
  }
}