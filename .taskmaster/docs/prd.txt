<context>
공연 예약 시스템 백엔드 명세서

시스템 흐름 개요

공연 티켓 예약 시스템은 OpenResty (Nginx 기반 프록시), Redis, Salvo 애플리케이션 서버, PostgreSQL 데이터베이스로 구성됩니다. 전체 흐름은 다음과 같습니다:
	1.	클라이언트 요청: 사용자가 /api/v1/seats/reservation 엔드포인트로 POST 요청을 보냅니다. 요청에는 사용자 식별자(X-User-Id 헤더)와 전화번호 등의 정보가 포함됩니다.
	2.	OpenResty 단계 – 중복 요청 필터링: 클라이언트 요청이 OpenResty에 도착하면 access_by_lua를 통해 Lua 스크립트가 실행됩니다. 이 Lua 코드에서 요청 헤더의 X-User-Id와 클라이언트 IP 주소(예: ngx.var.remote_addr)를 추출한 뒤 Redis에 조회하여 동일 사용자 혹은 동일 IP의 중복 동시 요청인지 검사합니다. 이 과정은 Redis Lua 스크립트를 활용하여 원자적으로 처리되며, 중복으로 판단되면 OpenResty가 즉시 HTTP 409 Conflict 응답으로 요청을 종료합니다. 중복이 아닌 경우에만 요청이 Salvo 서버로 프록시되어 전달됩니다.
	3.	Salvo 단계 – 좌석 순번 할당: OpenResty 필터를 통과한 요청만 Salvo 애플리케이션 서버로 도착합니다. Salvo 서버는 먼저 Redis의 전역 시퀀스 키(e.g. fcfs:seq)에 대해 INCR 명령을 호출하여 새로운 좌석 시도 번호를 발급받습니다. INCR 명령은 지정한 키의 값을 1 증가시키며, 증가된 새 값을 반환합니다 ￼. 이 반환된 값이 곧 좌석 번호로 간주되며(현재 시스템에서는 좌석 1번부터 9번까지 존재), 해당 순번의 좌석을 예약 시도하게 됩니다. 예를 들어 처음 들어온 요청은 fcfs:seq값을 1로 설정하고 좌석 1번을 시도하고, 다음 요청은 2번 좌석을 시도하는 식으로 선입선출(First-Come-First-Served) 순번이 부여됩니다.
	4.	좌석 예약 처리 (PostgreSQL): Salvo 서버는 Redis로부터 받은 좌석 번호로 PostgreSQL 데이터베이스의 seats 테이블을 조회합니다. seats 테이블은 좌석별 상태를 저장하며, 스키마 구조는 다음과 같습니다:

pub struct Model {
    pub id: i32,                   // 좌석 번호 (기본 키)
    pub status: bool,              // 예약 완료 여부 (true = 예약됨, false = 비어있음)
    pub reserved_by: Option<String>, // 예약자 ID (없으면 NULL)
    pub phone: Option<String>,    // 예약자 전화번호 (없으면 NULL)
}

Salvo 서버는 해당 id 좌석의 status 값을 확인합니다. 만약 status = false (예약 가능 좌석)이라면, 좌석을 현재 사용자에게 예약 확정하기 위해 status=true, reserved_by=<사용자ID>, phone=<전화번호>로 업데이트를 시도합니다. 반대로 좌석의 status가 이미 true(다른 요청에 의해 예약됨)인 경우, 해당 좌석은 이미 선점된 것이므로 예약 실패 처리를 합니다.

	5.	DB 동시성 및 좌석 상태 업데이트: 좌석 예약은 동시성 이슈 없이 안전하게 처리되어야 합니다. 이를 위해 가능한 한 단일 트랜잭션 또는 조건부 갱신을 사용합니다. 예를 들어, PostgreSQL에서는 한 쿼리로 조건부 업데이트를 수행할 수 있습니다. UPDATE seats SET ... WHERE id = <좌석번호> AND status = false RETURNING * 형태를 사용하면, 주어진 좌석이 아직 비어있는 경우에만 업데이트가 이뤄지고 그 결과 행을 반환합니다. WHERE 절의 조건을 만족하는 행만 업데이트되므로, 조건(status = false)이 거짓이면 아무 행도 갱신되지 않습니다 ￼. 이 방식으로 트랜잭션 전체를 잠그지 않고도 동시에 같은 좌석을 두 번 예약하는 일을 방지할 수 있습니다. (필요시 SELECT ... FOR UPDATE 등을 사용한 명시적 트랜잭션으로도 구현 가능하지만, 단일 UPDATE로 충분히 원자적 갱신을 보장할 수 있습니다.)
	6.	응답 생성: Salvo 서버는 좌석 업데이트 결과를 바탕으로 클라이언트에 보낼 JSON 응답을 생성합니다.
	•	좌석이 성공적으로 예약된 경우에는 HTTP 200 OK와 함께 { "success": true, "seat": <좌석번호> } 형태의 JSON을 반환합니다. 예: { "success": true, "seat": 5 } (5번 좌석 예약 성공).
	•	좌석이 이미 예약된 경우(즉, 예약 실패 시)에도 HTTP 200 OK로 응답하되, JSON 필드에서 실패를 표시합니다. 예를 들어 좌석 3번이 이미 예약되어 있었다면 { "success": false, "reason": "already reserved", "seat": 3 }처럼 success를 false로 표시하고 실패 원인을 명시합니다. 이때 좌석 번호는 시도한 번호를 함께 알려줍니다.
	•	만약 발급된 좌석 번호가 시스템에 없는 번호(예: 9번까지 모두 매진된 후 10번 순번이 나온 경우)라면 좌석 없음으로 간주하여 실패 응답을 보냅니다. 이 경우 { "success": false, "reason": "sold out" } 등의 형태로 모든 좌석이 소진되었음을 전달할 수 있습니다.
	7.	좌석 현황 조회: 예약이 완료되든 실패하든, 클라이언트는 별도의 좌석 상태 조회 API(/api/v1/seats)를 통해 현재 남은 좌석들을 확인할 수 있습니다. 이 조회는 실시간 데이터 동기화를 대신하는 것으로, seats 테이블을 조회하여 각 좌석의 상태를 반환합니다. 예를 들어, 응답으로 [ { "id": 1, "status": true }, { "id": 2, "status": false }, ... ] 와 같이 좌석별 예약 여부 목록을 제공하며, status: true인 좌석은 예약 완료 좌석을, false는 아직 남아있는 좌석을 의미합니다. (이 API는 단순 조회이므로 OpenResty의 중복 요청 필터를 거치지 않고 Salvo 서버에서 직접 처리합니다.)

OpenResty 설정 요약

OpenResty는 Nginx에 Lua 엔진을 내장하여 요청별로 사용자 정의 Lua 스크립트를 실행할 수 있게 합니다 ￼ ￼. 본 시스템에서는 OpenResty를 프록시로 사용하여 예약 요청의 전처리를 수행합니다. 관련 설정은 대략 다음과 같습니다:
	•	접근 제어 Lua: /api/v1/seats/reservation 경로에 대해 access_by_lua_block 지시어를 사용합니다. 이 블록 안에 중복 요청을 차단하는 Lua 코드를 작성합니다. access_by_lua는 클라이언트 요청이 백엔드(업스트림)로 넘어가기 전에 실행되므로, 여기에서 조건에 따라 요청을 차단할 수 있습니다.
	•	Lua를 통한 Redis 연결: Lua 코드 내부에서 Redis에 연결하기 위해 OpenResty의 lua-resty-redis 모듈을 사용합니다. 예를 들어 Lua 코드에서 local redis = require "resty.redis"로 Redis 클라이언트를 불러오고, redis:new() 및 redis:connect("<Redis서버주소>", 6379) 방식으로 Redis에 접속합니다 ￼. 연결 오류 시 Nginx 단계에서 에러를 반환하고, 성공 시 Redis 명령을 사용할 수 있습니다. (Redis 접속 정보는 설정에 하드코딩하거나, 환경변수/별도 설정으로 관리합니다.)
	•	중복 요청 식별자 구성: Lua 스크립트는 요청의 X-User-Id 헤더와 클라이언트 IP를 조합하여 Redis 키를 만듭니다. 예를 들어 user:<사용자ID> 및 ip:<클라이언트IP> 두 가지 키를 사용할 수 있습니다. 이 두 가지를 모두 체크하여 동일 사용자나 동일 IP에서 동시에 오는 다중 요청을 탐지합니다.
	•	Redis Lua EVAL 활용: Redis로 두 개 키의 존재 여부를 **원자적(atomic)**으로 검사하기 위해 Lua 스크립트를 Redis 측에 EVAL로 실행합니다. Redis의 Lua 스크립트는 실행되는 동안 다른 명령이 개입할 수 없어서 트랜잭션과 동일한 원자성을 보장합니다 ￼. 이를 통해 키 존재 체크와 설정을 한 번의 Redis 연산으로 수행합니다.
	•	Lua 스크립트 논리: Redis에 보낼 Lua 스크립트의 로직은 다음과 같습니다 (의사 코드):

-- KEYS[1] = "dup:user:<사용자ID>"
-- KEYS[2] = "dup:ip:<클라이언트IP>"
if redis.call('EXISTS', KEYS[1]) == 1 or redis.call('EXISTS', KEYS[2]) == 1 then
    return 1  -- 중복 요청 있음
else
    redis.call('SET', KEYS[1], 1)
    redis.call('SET', KEYS[2], 1)
    redis.call('EXPIRE', KEYS[1], 5)  -- TTL 5초 (예시)
    redis.call('EXPIRE', KEYS[2], 5)
    return 0  -- 새 요청으로 허용
end

위 스크립트는 주어진 두 키 중 하나라도 이미 존재하면 1을 반환하여 중복임을 표시하고, 둘 다 없으면 두 키를 설정한 뒤 0을 반환합니다. 키 값으로 1을 저장하고 간단히 짧은 TTL(여기서는 5초)을 건 이유는, 요청 처리가 끝난 후 자동 만료되도록 하기 위함입니다. (TTL은 상황에 맞게 조정 가능합니다. 또는 OpenResty에서 log_by_lua 단계 등에서 요청 완료 시 직접 키를 삭제할 수도 있습니다.)

	•	Nginx 단계 응답 제어: Lua 스크립트 실행 결과에 따라 OpenResty가 요청 흐름을 제어합니다. Redis Lua 스크립트가 1을 반환하면 이는 중복된 동시 요청이므로, ngx.exit(409)를 호출해 HTTP 409 Conflict 응답을 즉시 반환하고 해당 요청 처리를 종료합니다. 이때 응답 바디는 필요에 따라 JSON으로 {"success": false, "reason": "duplicate request"} 등을 보낼 수 있지만, 간단히 상태 코드만 돌려줘도 무방합니다.
반대로 Lua 스크립트가 0을 반환하면 중복이 아님을 뜻하므로, OpenResty는 요청을 그대로 Salvo 서버로 프록시 전달합니다. Nginx 설정에서는 proxy_pass http://<salvo서버주소> 등을 통해 백엔드 Salvo로 요청이 넘어가도록 합니다.
	•	기타 설정: OpenResty 설정에는 서버 블록 내에 client_body_buffer_size, proxy_buffering off 등의 튜닝을 할 수 있으며, 필요한 경우 Rate Limiting이나 IP 블록 등 추가적인 Nginx 모듈 설정과 함께 동작시킬 수 있습니다. 하지만 본 명세의 핵심은 중복 클릭/요청 방지이므로 기타 설정은 기본값을 따른다고 가정합니다.

요약하면, OpenResty 단계에서 Lua를 이용한 Redis 조회로 중복 요청을 선제적으로 걸러내어 백엔드로 불필요한 부하를 줄이고, 한 사용자/한 IP 당 하나의 예약 시도만 진행되도록 보장합니다 ￼. 이 접근은 특히 동시에 많은 트래픽이 몰릴 때 중복 처리로 인한 데이터 충돌을 예방해주며, Redis Lua 스크립트 덕분에 체크&세트 연산이 원자적으로 이뤄져 신뢰성을 높입니다.

Redis Lua 로직 요약

위 OpenResty 설정에서 사용된 Redis Lua 스크립트에 대해 조금 더 자세히 설명합니다. 이 스크립트는 중복 요청 필터링을 위한 것으로, 두 개의 키 (사용자 ID 기반 키와 IP 기반 키)를 동시에 검사하고 설정합니다. 주요 내용은 다음과 같습니다:
	•	원자성 보장: Redis에서 Lua 스크립트를 EVAL로 실행하면 그 스크립트는 실행되는 동안 다른 Redis 명령이 개입하지 못하며, 마치 Redis 트랜잭션(MULTI/EXEC)처럼 동작합니다 ￼. 따라서 다수의 클라이언트가 거의 동시에 Lua 스크립트를 호출하더라도, Redis가 직렬화하여 한 번에 하나씩 처리하므로 레이스 컨디션 없이 정확한 중복 판단이 가능합니다.
	•	키 설계: KEYS 배열로 전달되는 두 키는 각각 사용자와 IP에 대응합니다. 예를 들어 사용자 ID가 “user123”, IP가 “1.2.3.4”인 경우, KEYS[1] = "dup:user:user123", KEYS[2] = "dup:ip:1.2.3.4"와 같이 정합니다. (네이밍은 구현에 따라 달라질 수 있습니다.) 이렇게 구분하여 설정하는 이유는, 동일 사용자가 동시에 두 번 요청하거나 동일 IP에서 여러 요청이 올 때 모두 잡아내기 위함입니다.
	•	중복 판단: Lua 스크립트 내부에서는 redis.call('EXISTS', KEYS[1])와 EXISTS KEYS[2]를 이용해 해당 키들의 존재 여부를 확인합니다. 둘 중 하나라도 이미 Redis에 존재한다는 것은 같은 사용자나 동일 IP로 이미 진행 중인 예약 시도가 있다는 뜻입니다. 이때는 곧바로 return 1로 종료하여 호출측(OpenResty)에 중복임을 알립니다.
	•	잠금 설정: 두 키 모두 존재하지 않을 경우, 현재 요청이 처음이라는 의미이므로 redis.call('SET', KEYS[1], 1) 및 redis.call('SET', KEYS[2], 1)로 두 키를 설정합니다. 굳이 값은 중요하지 않으므로 1이나 "lock" 등 임의의 값을 써도 됩니다. 중요한 것은 이후 redis.call('EXPIRE', KEYS[<i>], <TTL>)을 통해 **TTL(유효시간)**을 짧게 부여하는 것입니다. 예를 들어 5초로 설정하면, 키는 5초 후 자동 삭제되어 중복 잠금이 해제됩니다. 이렇게 하면 Salvo 서버에서 예약 처리가 이루어진 뒤 일정 시간 내에 키가 지워져, 사용자가 다음 예약 시도를 할 수 있게 됩니다. (만약 TTL을 너무 길게 잡으면, 이전 요청이 끝났음에도 키가 남아있어 불필요하게 사용자를 막을 수 있으므로 주의해야 합니다.)
	•	반환 값: 스크립트가 마지막에 return 0 또는 1 등의 값을 반환하면, OpenResty의 Lua 코드에서 해당 값을 받아 분기 처리를 합니다. 0인 경우에는 중복 아님, 1인 경우 중복임을 나타내도록 약속합니다. 필요하다면 Lua 스크립트에서 문자열이나 상세한 메시지를 반환하게 할 수도 있지만, OpenResty 단계에서는 복잡한 로직 없이 숫자 코드로 처리하는 편이 단순합니다.
	•	확장: 현재 구현은 사용자별, IP별 이중 조건으로 중복을 판단하지만, 운영 상황에 따라 정책을 조정할 수 있습니다. 예를 들어 IP 기반 제한을 제거하면(즉 사용자만 고려) 동일 사용자의 중복 클릭만 막게 되므로, 같은 IP 내 다른 사용자는 동시에 요청할 수 있게 됩니다. 반대로 IP만 고려하면 로그인 여부와 무관하게 같은 IP에서 하나의 요청만 허용합니다. 또, 시간 창(window)을 조절하여 **과도한 트래픽 유입 제어(rate limiting)**에도 활용할 수 있습니다. 이러한 부분은 Redis Lua 스크립트를 수정하거나 Lua에서 Redis 명령 조합을 바꾸는 것으로 구현 가능합니다.

정리하면, Redis Lua 스크립트는 중복 요청을 선별하고 잠금 키를 설정하는 역할을 수행합니다. 이를 통해 분산 환경에서도 한 사용자나 한 IP가 동시에 한 번만 좌석 예약을 시도할 수 있으며, 그 사이 다른 중복 시도는 즉시 차단됩니다. 실제 사례로, Lua 스크립트를 활용하여 좌석 선택을 원자적으로 처리하면 여러 사용자가 동시에 같은 좌석을 요청해도 단 한 명만 성공하고 나머지는 실패하도록 만들 수 있습니다 ￼. 이러한 원자적 처리 덕분에 공정한 선착순 예약이 가능해집니다.

Salvo 예약 처리 흐름

Salvo는 Rust 기반의 웹 서버 프레임워크로 구현된 애플리케이션 서버입니다. OpenResty를 통과한 예약 요청은 Salvo 서버의 /api/v1/seats/reservation 핸들러로 전달되어 실제 예약 비즈니스 로직이 실행됩니다. Salvo에서의 처리 흐름을 단계별로 설명하면 다음과 같습니다:
	1.	요청 수신 및 파싱: Salvo는 전달된 HTTP 요청에서 필요한 정보를 추출합니다. 여기에는 예약자 식별자(ID)와 전화번호가 포함됩니다. X-User-Id 헤더는 OpenResty에서 넘겨주었다면 이를 사용하고, 전화번호는 일반적으로 요청 바디(JSON)에 포함된 필드를 파싱합니다. (혹은 모두 JSON 바디로 전달받을 수도 있습니다. 구현 방식에 따라 다를 수 있지만, 핵심은 누가 어떤 번호로 예약하는지를 알아내는 것입니다.)
	2.	좌석 번호 할당 (Redis 시퀀스): Salvo는 Redis에 전역 좌석 시퀀스를 증가시키도록 명령합니다. Redis의 INCR fcfs:seq 명령을 사용하며, 여기서 fcfs:seq 키는 공연 좌석의 전역 순번을 나타냅니다. INCR은 해당 키의 값을 원자적으로 +1 증가시키고 증가 후의 새로운 값을 반환합니다 ￼. 예를 들어 현재 값이 0이거나 키가 없다면 INCR 호출 후 1이 반환되고, 다음 호출 시 2가 반환되는 식입니다. 이 반환된 정수가 곧 이번 요청이 시도할 좌석 번호가 됩니다.
	•	첫 번째 요청 -> fcfs:seq가 1로 설정되고 좌석 #1 시도
	•	두 번째 요청 -> 2 반환, 좌석 #2 시도
…
	•	아홉 번째 요청 -> 9 반환, 좌석 #9 시도
	•	열 번째 요청 -> 10 반환, 좌석 #10 시도 (이 경우 좌석 10은 존재하지 않으므로 실패 처리)
이렇게 Redis를 이용함으로써 분산 환경에서도 좌석 번호 부여를 중앙에서 순차적으로 관리할 수 있습니다. Redis 자체가 단일 쓰레드로 작동하므로, 동시에 여러 요청이 와도 INCR 명령들은 차례대로 처리되어 중복된 번호가 나올 가능성이 없습니다. (예: 동시에 두 요청이 INCR해도 하나는 7, 다른 하나는 8 식으로 각각 고유한 번호를 받습니다.)
	3.	좌석 상태 조회 (DB): Redis로부터 좌석 번호를 부여받았다면, Salvo는 PostgreSQL 데이터베이스의 seats 테이블에서 해당 좌석(id 컬럼) 행을 조회합니다. 이를 통해 현재 그 좌석이 비어있는지(status = false) 혹은 이미 예약되었는지(status = true)를 확인합니다.
	•	좌석 존재 여부: 만약 발급된 좌석 번호가 seats 테이블에 존재하지 않는다면 (예: 좌석 10 번을 요청했는데 좌석 개수가 9개뿐인 경우), 이는 남은 좌석이 없다는 뜻입니다. 이때는 바로 예약 실패로 처리하고 더 이상 진행하지 않습니다. (아래 응답 생성 단계에서 실패 응답을 생성합니다.)
	•	좌석 미예약 상태: 조회 결과 status = false인 좌석이라면 아직 예약되지 않았으므로, 해당 좌석을 이번 사용자에게 예약하기 위한 갱신 처리를 수행합니다.
	•	좌석 이미 예약됨: 조회 결과 status = true인 경우 이미 다른 사용자에 의해 예약 완료된 좌석입니다. 이 경우 예약을 진행할 수 없으므로, Salvo는 이 요청을 예약 실패로 간주합니다.
	4.	좌석 예약 시도 (DB 갱신): 좌석이 빈 것으로 확인되었다면, Salvo 서버는 즉시 좌석 예약 완료로 상태를 변경하는 데이터베이스 업데이트를 시도합니다. 이때 동시성으로 인한 오류 없이 정확히 하나의 요청만 좌석을 선점하게 하기 위해, 다음과 같은 조건부 업데이트 또는 트랜잭션을 사용합니다:
	•	조건부 UPDATE 예시:

UPDATE seats
   SET status = true,
       reserved_by = '<현재사용자ID>',
       phone = '<전화번호>'
 WHERE id = <좌석번호>
   AND status = false
RETURNING *;

이 쿼리는 주어진 id에 대해 status가 아직 false인 경우에만 true로 바꾸고 예약자 정보를 업데이트합니다. WHERE 조건을 만족하지 않으면 아무 행도 갱신되지 않고 종료됩니다 ￼. RETURNING * 절을 넣었으므로 업데이트가 성공하면 해당 행을 반환하며, Salvo는 이를 통해 업데이트 결과를 확인할 수 있습니다. (예를 들어 업데이트된 좌석 행을 받아 좌석 번호 및 예약자 정보를 확인 가능하지만, 응답에는 좌석 번호 정도만 사용하면 됩니다.)
	•	이 쿼리 결과 업데이트된 행이 반환되었다면 예약 성공을 의미합니다. 해당 좌석은 이제 현재 사용자 것으로 예약 상태가 되었음을 확인한 것이고, 바로 응답을 준비하면 됩니다.
	•	만약 영향을 받은 행이 0개라면, 이는 status = false 조건을 만족하는 행이 없었다는 뜻입니다. 즉, 좌석이 이미 누군가에 의해 예약되어 더 이상 업데이트할 수 없었거나 좌석 번호가 유효하지 않은 경우입니다. 이때 Salvo는 해당 요청을 예약 실패로 처리해야 합니다. (좌석 존재 여부는 앞서 확인하므로 주로 동시에 같은 좌석을 집은 예외적 상황에서 발생할 수 있지만, 우리 시나리오의 전역 시퀀스 방식에서는 같은 좌석을 두 번 시도하는 케이스가 거의 없기 때문에 이 조건이 실패하는 경우는 드뭅니다. 그래도 안전망으로 체크합니다.)

	•	트랜잭션 잠금 대안: 위의 단일 UPDATE로도 충분하지만, 다른 방법으로는 명시적 트랜잭션을 사용해 좌석 행을 잠근 후 상태를 바꾸는 것입니다. 예를 들어, BEGIN; SELECT * FROM seats WHERE id=<n> FOR UPDATE; ... UPDATE ...; COMMIT; 순으로 수행하면 SELECT FOR UPDATE 시점에 해당 행이 락 걸리고 이후 상태를 변경합니다 ￼. 이 방법은 명시적이지만, 동시에 트랜잭션이 몰릴 경우 데드락 등이 발생할 수 있어 단일 UPDATE 방식이 더 간결하고 빠릅니다.
결과적으로, Salvo는 좌석 상태가 false인 경우에만 true로 변경함으로써 동시성 문제 없이 한 좌석에 하나의 예약만 이뤄지도록 보장합니다.

	5.	응답 생성 및 전송: Salvo 서버는 DB 처리 결과에 따라 클라이언트에 반환할 응답 내용을 준비합니다. HTTP 상태 코드는 요청 자체는 정상적으로 처리되었으므로 항상 200 OK를 사용합니다 (단, OpenResty 단계에서 차단된 경우는 409로 이미 응답함). 응답 바디는 JSON 포맷으로, 핵심 필드로 예약 성공 여부와 관련 정보를 담습니다:
	•	성공 케이스: 좌석이 확보된 경우 { "success": true, "seat": <좌석번호>, "reservedBy": "<사용자ID>" }와 같은 내용을 포함할 수 있습니다. reservedBy나 phone 등의 세부 정보는 선택사항이며, 일반적인 클라이언트라면 자신이 요청한 것이므로 굳이 ID를 다시 보내지 않아도 무방합니다. 최소한 좌석 번호는 알려주는 것이 좋습니다. 예시:

{
  "success": true,
  "seat": 3
}

위 응답은 3번 좌석 예약에 성공했다는 의미입니다.

	•	실패 케이스 (좌석 선점됨): 요청한 좌석이 이미 예약된 경우 { "success": false, "reason": "already reserved", "seat": <좌석번호> } 형태로 응답합니다. reason 필드에는 실패 원인을 명시하고, seat에는 시도한 좌석 번호를 넣어 사용자가 어느 좌석을 시도했다 실패했는지 알 수 있게 합니다. 예시:

{
  "success": false,
  "reason": "already reserved",
  "seat": 3
}

만약 이러한 실패가 발생했다면 사용자는 /api/v1/seats 조회 API 등을 통해 남은 좌석을 확인한 후 재시도를 할 수 있습니다 (혹은 시스템이 자동으로 다음 좌석을 시도하지 않고 해당 요청을 종료하는 설계임을 주의해야 합니다).

	•	실패 케이스 (좌석 없음): 발급된 좌석 번호가 존재하지 않는 경우나 모든 좌석이 찬 경우에는 { "success": false, "reason": "sold out" } 또는 { "success": false, "reason": "no seat available" } 같은 응답을 보냅니다. 좌석 번호를 굳이 포함할 필요는 없으며, 이 상황은 남은 좌석이 없어서 더 이상 진행 불가임을 알려줍니다.
	•	기타 고려: 오류 처리로서, DB나 Redis에 연결 실패 등이 발생하면 500 에러를 반환하거나 별도 에러 메시지를 보내야 하지만, 본 명세에서는 정상 경로에 집중하겠습니다.
응답이 준비되면 Salvo 서버는 JSON 직렬화하여 HTTP 응답을 반환합니다. OpenResty는 단순히 이 응답을 클라이언트에게 그대로 전달합니다. 이후 OpenResty 단계의 log_by_lua 등에서 Redis의 중복 처리 키를 제거하거나(만약 TTL을 매우 짧게 주지 않았다면) 로그를 남기는 작업을 수행할 수 있습니다.

PostgreSQL 트랜잭션 처리 쿼리 예시

위에서 언급한 PostgreSQL 좌석 예약 갱신에 사용되는 SQL 쿼리에 대해 구체적인 예시와 고려사항을 정리합니다. 목표는 동시에 여러 요청이 같은 좌석을 두고 경쟁하더라도 정확히 한 건만 성공 처리되도록 하는 것입니다.
	•	조건부 UPDATE 활용: 가장 간단하면서 효율적인 방식은 하나의 UPDATE 문에 조건을 거는 것입니다. 예를 들어 5번 좌석을 사용자 "alice"가 전화번호 "010-1234-5678"로 예약하려는 상황에서의 쿼리는 다음과 같습니다:

UPDATE seats
   SET status = TRUE,
       reserved_by = 'alice',
       phone = '010-1234-5678'
 WHERE id = 5
   AND status = FALSE
 RETURNING id, reserved_by, phone;

이 쿼리는 좌석 5번의 status가 FALSE인 경우에만 TRUE로 업데이트하고, 동시에 reserved_by와 phone 정보를 기록합니다. RETURNING 절을 통해, 실제 갱신이 이루어졌다면 갱신된 행의 주요 정보를 반환받을 수 있습니다 (여기선 id와 reserved_by, phone을 반환). PostgreSQL에서 WHERE 조건은 해당 조건을 만족하는 행에만 연산을 적용하므로, status = FALSE 조건 덕분에 이미 TRUE로 변경된 좌석은 업데이트되지 않습니다 ￼. 한 트랜잭션 내에서 이 쿼리는 원자적으로 수행되어, 만약 두 개의 세션이 동시에 이 쿼리를 실행하더라도 PostgreSQL의 행 잠금 메커니즘에 의해 순차적으로 처리됩니다. 결국 먼저 온 쿼리가 좌석을 차지하면 두 번째 쿼리는 WHERE 조건을 만족하지 않아서 0행 업데이트로 끝나게 됩니다.
Salvo 서버 측에서는 이 쿼리의 결과로 반환된 행이 있는지 여부로 성공/실패를 판단하면 됩니다. 반환 행이 있으면 성공 (해당 행의 데이터를 이용해 응답 생성), 반환된 행이 없으면 실패 (좌석이 이미 예약됨).

	•	SELECT FOR UPDATE (트랜잭션): 또다른 방법은 두 단계로 처리하는 것입니다. 먼저 트랜잭션을 시작한 뒤 원하는 좌석 행을 SELECT ... FOR UPDATE로 조회하여 행 락을 겁니다. 그런 다음 애플리케이션 레벨에서 status 값을 검사하고, false이면 UPDATE를 실행, true이면 롤백하거나 예외 처리합니다. 예를 들어:

BEGIN;
SELECT status FROM seats WHERE id = 5 FOR UPDATE;
-- 애플리케이션이 결과 읽어서 status 확인
UPDATE seats
   SET status = TRUE,
       reserved_by = 'alice',
       phone = '010-1234-5678'
 WHERE id = 5;
COMMIT;

이러한 방법은 이해하기 직관적이지만, 프로그래밍 레벨에서 트랜잭션 관리가 필요하고, 잘못하면 데드락 회피를 위한 재시도 로직도 고려해야 합니다 ￼. 반면 앞서 소개한 조건부 UPDATE는 데이터베이스가 내부적으로 알아서 처리를 시도하고 필요시 실패(0행 수정)로 반환하기 때문에 애플리케이션 로직이 단순해집니다.

	•	실패 시 재시도: 만약 조건부 업데이트가 실패(0행 수정)한 경우, Salvo는 이를 감지하여 해당 좌석 번호가 이미 예약되었음을 의미한다고 판단합니다. 이때 특별히 재시도를 같은 요청 내에서 자동으로 하지는 않습니다(첫번째 실패 응답 후 사용자가 다시 요청해야 함). 만일 한 번의 요청에서 자동으로 다음 좌석을 시도하게 하고 싶다면, 실패시 INCR을 다시 호출하여 다음 좌석번호로 위 과정을 반복하는 것도 생각해볼 수 있습니다. 그러나 이러한 자동 재시도는 클라이언트 입장에서 의도치 않은 동작일 수 있으므로, 본 시스템에서는 요청 1건당 좌석 1개 시도라는 규칙을 유지합니다.
	•	데이터 무결성: seats 테이블의 id는 기본 키이므로 중복될 수 없고, 하나의 좌석 행이 하나의 예약 상태만 가질 수 있습니다. 만약 좌석이 하나만 예약될 수 있다는 비즈니스 제약을 데이터베이스 차원에서 보장하려면, status를 boolean으로 두는 대신 별도 reservations 테이블을 두고 좌석 ID에 unique 제약을 거는 방식도 있습니다. 하지만 지금 구조에선 id가 PK이자 좌석 고유 식별자이므로, 단일 행 업데이트만으로 충분히 무결성을 지킬 수 있습니다. 추가로 CHECK (status IN (0,1))나 트리거 등으로 true/false 이외 값이 못 들어가게 하는 정도는 적용 가능하겠습니다.
	•	예외 처리: 쿼리 수행 중 예기치 않은 에러 (예: DB 연결 끊김, 기타 제약 조건 위배 등)가 발생하면 트랜잭션은 롤백되어야 하며, Salvo는 500 오류나 적절한 메시지를 반환하도록 해야 합니다. 이러한 예외는 일반적인 운영 상황에선 드물겠지만, 시스템 신뢰성을 위해 로깅 및 알림이 필요합니다.

결론적으로, PostgreSQL에서는 단 한번의 조건부 UPDATE로 안전한 좌석 예약 처리가 가능하며, 이 방법이 현재 시스템에 채택되었습니다. 이는 구현이 간결하고 성능 면에서도 유리합니다. 데이터베이스 엔진 레벨에서 필요한 행에만 락을 걸어주기 때문에 동시 다발적인 요청도 처리할 수 있으며, Redis INCR를 통한 좌석 분배와 함께 동작하여 선착순 예약의 정확성을 보장합니다.

API 응답 명세 예시

시스템의 주요 API인 예약 API (POST /api/v1/seats/reservation)와 좌석 조회 API (GET /api/v1/seats)의 응답 형식을 예시와 함께 설명합니다. 모든 응답 데이터는 JSON 포맷이며, UTF-8 인코딩을 사용합니다.
	•	예약 API (POST /api/v1/seats/reservation): 좌석 예약 요청에 대한 응답. 앞서 언급했듯 HTTP 상태 코드는 200 OK를 기본으로 합니다 (중복 요청 차단의 409 응답을 제외). JSON 바디의 구조는 다음 필드를 가집니다:
	•	success: 불리언(boolean) 값으로, 예약 성공 여부를 나타냅니다. true이면 좌석 예약 성공, false이면 예약되지 않았음을 의미합니다.
	•	seat: 정수(integer) 값으로, 해당 요청이 할당받은 좌석 번호를 나타냅니다. success:true인 경우 실제 예약된 좌석 번호이며, success:false인 경우에는 예약을 시도했던 좌석 번호를 나타냅니다. (좌석이 존재하지 않는 경우 이 필드는 생략될 수도 있습니다.)
	•	reason: 문자열(string) 값으로, success:false일 때만 존재하며 실패 원인을 설명합니다. 예를 들면 "already reserved" (이미 예약됨), "sold out" (모든 좌석 매진) 등이 들어갈 수 있습니다. 클라이언트는 이 메시지를 이용해 사용자에게 실패 사유를 전달하거나 다음 조치를 취할 수 있습니다.
예시 응답:
	•	예약 성공 시 (예: 5번 좌석 성공):

HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8

{
  "success": true,
  "seat": 5
}

위는 좌석 5번을 성공적으로 예약했음을 나타냅니다. reason 필드는 성공이므로 없습니다.

	•	예약 실패 시 – 이미 예약된 좌석 (예: 3번 좌석 실패):

HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8

{
  "success": false,
  "reason": "already reserved",
  "seat": 3
}

이 경우 좌석 3번을 시도했으나 이미 선점되어 실패한 상황입니다. 클라이언트는 "already reserved" 메시지를 보고 사용자에게 해당 좌석이 이미 예약되었음을 알릴 수 있습니다.

	•	예약 실패 시 – 좌석 없음/매진:

HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8

{
  "success": false,
  "reason": "sold out"
}

예를 들어 10번째 좌석을 시도했으나 9개밖에 좌석이 없어 실패한 경우입니다. 혹은 남은 좌석이 전혀 없을 때의 응답으로도 사용할 수 있습니다. seat 필드는 의미가 없으므로 포함되지 않았습니다.

	•	중복 요청 차단 시 (OpenResty에서 409 응답):

HTTP/1.1 409 Conflict
Content-Type: application/json; charset=utf-8

{
  "success": false,
  "reason": "duplicate request"
}

이 응답은 동일 사용자/IP의 또 다른 요청이 동시에 감지되었을 때 프록시 단계에서 반환되는 것입니다. 일반적으로 클라이언트 앱이 이를 직접 보게 되지는 않고, 잘 설계된 앱이라면 사용자의 중복 입력을 클라이언트 수준에서도 막겠지만, 혹시 발생할 경우 이런 응답이 올 수 있습니다. 409 Conflict는 표준 HTTP 상태코드이며, 본 시스템에서는 “중복된 요청”의 의미로 사용했습니다.

	•	좌석 조회 API (GET /api/v1/seats): 현재 예약 가능한 좌석과 예약 완료된 좌석의 현황을 제공합니다. 응답은 HTTP 200 OK이며, JSON의 최상위에 좌석 리스트가 포함됩니다. 좌석 리스트는 좌석 객체들의 배열로 표현합니다. 각 객체는 다음 필드를 갖습니다:
	•	id: 좌석 번호 (1부터 시작하는 정수).
	•	status: 해당 좌석의 예약 상태 (불리언). true이면 예약 완료(점유된 좌석), false이면 아직 예약 가능(비어 있는 좌석).
	•	(옵션) reserved_by: 좌석을 예약한 사용자의 ID. 이 필드는 보안이나 개인정보 이슈로 기본 제공하지 않을 수도 있습니다. 일반 사용자용 API에는 굳이 다른 사용자의 ID를 노출할 필요가 없으므로 생략 가능합니다. 관리자나 내부 모니터링 용도라면 포함할 수 있습니다.
	•	(옵션) phone: 예약자의 전화번호. 이 역시 일반 조회 API에는 포함되지 않습니다.
예시 응답:

HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8

[
  { "id": 1, "status": true },
  { "id": 2, "status": false },
  { "id": 3, "status": true },
  { "id": 4, "status": false },
  { "id": 5, "status": false },
  { "id": 6, "status": false },
  { "id": 7, "status": false },
  { "id": 8, "status": false },
  { "id": 9, "status": false }
]

이 예시는 1번과 3번 좌석은 이미 예약되었고, 나머지 좌석은 비어 있음을 보여줍니다. 클라이언트는 이 정보를 사용하여 예약 가능한 좌석 목록을 갱신하거나, 실시간 좌석 현황을 사용자에게 안내할 수 있습니다.
조회 API는 캐시를 적용하거나 주기적으로 갱신되는 형태로 운영할 수 있습니다. 예약 상황이 실시간으로 자주 변하지 않는다면 응답에 Cache-Control 헤더를 설정해 수 초~수십 초 간 브라우저나 중간 프록시가 캐시하도록 할 수도 있습니다. 다만, 너무 오랫동안 캐시하면 사용자가 이미 예약된 좌석을 예약 가능하다고 착각할 수 있으므로 적절한 값이 필요합니다.

	•	에러 응답 형식: 시스템 내부 오류(500번대)나 잘못된 요청(400번대)이 발생할 경우, JSON 형식으로 에러 메시지를 담을 수 있습니다. 예를 들어 500 Internal Server Error 시 { "success": false, "error": "internal error" }처럼 보낼 수 있고, 400 Bad Request (필수 필드 누락 등)는 { "success": false, "error": "bad request" } 등으로 표현할 수 있습니다. OpenResty나 Salvo에서 에러 핸들링을 일관된 형태로 구현하여 JSON으로 내려주는 것이 바람직합니다.

요약하면, API 응답은 클라이언트가 쉽게 처리할 수 있도록 일관된 구조의 JSON으로 제공됩니다. 성공/실패 여부와 필요한 정보를 명시적으로 담고 있으며, 이는 프론트엔드 또는 사용자에게 명확한 피드백을 주기 위한 것입니다.

확장 가능성에 대한 고려사항

현재 설계된 시스템은 비교적 단순한 선착순 좌석 예약 시나리오(좌석 9개 한정)에 맞춰져 있지만, 향후 요구 증가나 환경 변화에 대비하여 몇 가지 확장 및 개선 포인트를 고려할 수 있습니다:
	•	좌석 수 증가 및 공연 회차 추가: 현 단계에서는 fcfs:seq라는 하나의 전역 시퀀스로 모든 좌석 번호를 관리합니다. 만약 좌석 수가 크게 늘어나거나 여러 공연 회차(또는 여러 공연 종류)를 관리해야 한다면, 시퀀스 키 및 좌석 테이블을 분리해야 합니다. 예를 들어 공연마다 고유한 공연 ID를 두고, Redis 키를 fcfs:seq:<공연ID> 형태로 분리하면 각 공연별로 1번부터 좌석을 할당할 수 있습니다. PostgreSQL seats 테이블도 id만으로 식별하지 않고 (id를 좌석 고유번호로 두되) 별도로 show_id 컬럼 등을 추가해 해당 공연의 좌석임을 표시하거나, 아예 공연별 좌석 테이블을 둘 수도 있습니다. 이러한 구조 변경 시 Salvo 로직에서도 요청 입력에 공연 식별자가 포함되도록 하고, Redis 및 DB 쿼리에 그 ID를 고려하도록 수정해야 합니다.
	•	동시 요청 처리 및 병목: OpenResty + Redis 조합은 매우 높은 QPS(초당 요청 수)에서도 견딜 수 있게 설계되었습니다. Redis 자체는 메모리 기반이고 INCR 연산이나 Lua 스크립트 실행도 O(1) 복잡도로 매우 빠릅니다 ￼. 그러나 이론상 모든 예약 요청이 순차 시퀀스 할당을 기다려야 하므로, fcfs:seq 키에 대한 **경합(lock contention)**이 생길 수 있습니다. 수만 명이 동시에 몰리는 유명 공연 예약의 경우, Redis가 그 많은 INCR을 직렬로 처리해야 하므로 대기 시간이 늘어날 수 있습니다.
	•	이 문제를 완화하려면 Redis를 수평 확장(예: 클러스터링)하는 방안은 있지만, 단일 키에 대한 연산은 클러스터링으로도 분산이 어렵습니다. 대신 애플리케이션에서 멀티스레드 Salvo 인스턴스 여러 개를 두고, 모두 하나의 Redis에 붙여 요청을 처리하도록 하는 것이 일반적입니다. Redis 자체가 매우 빠르므로 병목 가능성은 낮으며, 오히려 DB 업데이트 처리 시간이 상대적인 병목이 될 수 있습니다.
	•	또한, 좌석이 매우 많아질 경우 (예: 9석 -> 900석, 9000석 등) 전체 완판까지 걸리는 시퀀스 수도 커집니다. 그러나 Redis INCR은 64비트 정수를 다루므로 9천이나 9만까지도 문제없습니다. 다만 좌석이 많아지면 예약 실패 응답의 비율도 올라갈 수 있습니다 (동시에 많은 사람들이 시도하면 일부는 이미 누군가 예약한 좌석번호를 받게 될 수 있으므로). 이를 개선하려면 좌석을 일괄적으로 여러 개 할당하는 등의 로직이 필요할 수 있지만, 그러면 선착순의 단순성이 깨지므로 신중한 고려가 필요합니다.
	•	OpenResty 중복 제한 정책 변경: 현재 동일 IP와 동일 사용자 두 가지 기준으로 중복 요청을 제한합니다. 이 방식은 대부분의 경우 유효하지만, 만약 하나의 IP에서 여러 사용자가 동시에 접속하는 상황(예: 가정이나 회사 공유 인터넷)에서는 다소 과도한 제한이 될 수 있습니다. 예를 들어 동일 IP 내 두 명의 다른 사용자가 동시에 예약을 시도하면, 한 명은 “duplicate request”로 차단될 수 있습니다. 이를 완화하려면 Redis Lua 스크립트를 수정하여 IP는 빼고 사용자만 체크하거나, 혹은 IP당 허용 동시 요청수를 늘리는 등의 변경이 필요합니다. 또한 현재 TTL로 잠금을 해제하고 있는데, 만약 예약 처리 시간이 TTL보다 길어질 경우(예: DB 지연) TTL이 만료돼 키가 지워지면 중복 검출이 풀려버리는 문제가 생길 수 있습니다. 보수적으로 TTL을 길게 잡자니 사용자 경험에 영향이 있고, 너무 짧게 잡자니 처리 시간에 따라 중복 검출 누락이 발생할 수 있습니다. 궁극적으로는 OpenResty에서 요청 완료 시점에 직접 키를 삭제하는 것이 가장 정확한 방법입니다. OpenResty의 log_by_lua 단계는 응답 전송 후 호출되므로, 여기서 Redis에 해당 키들을 DEL하면 TTL에 의존하지 않고도 정확히 잠금을 해제할 수 있습니다. 이 개선을 통해 중복 제한이 필요한 시간만큼만 걸리도록 조정할 수 있습니다.
	•	Salvo 확장 및 부하 분산: Salvo 애플리케이션 서버는 무상태(Stateless)로 설계되어 있습니다. 세션이나 기타 상태를 내부 메모리에 유지하지 않고, 필요한 데이터는 Redis/DB에서 가져오기 때문입니다. 따라서 Salvo 인스턴스를 여러 대 띄워 수평 확장하는 것이 가능합니다. Nginx(OpenResty)는 기본적으로 하나의 upstream으로 다수 백엔드를 설정하고 라운드로빈 등의 방식으로 부하를 분산할 수 있습니다. Redis INCR와 Lua 잠금은 공용 자원을 쓰므로 문제 없고, PostgreSQL은 여러 애플리케이션 인스턴스가 동시에 쿼리해도 자체적으로 동시성을 제어합니다. 다만 PostgreSQL의 커넥션 풀이나 Redis 커넥션 수 등은 증가하는 트래픽에 맞춰 조정해야 합니다.
	•	예약 실패 대응: 현재 설계에서는 한 번의 요청이 하나의 좌석 예약 시도를 합니다. 만약 실패하면 사용자가 다시 시도해야 하며, 그 사이에 좌석 현황을 확인하고 빈 좌석이 남아있는지 봐야 합니다. 향후 사용자 경험 개선을 위해 자동 재시도 로직을 도입할 수 있습니다. 예를 들어, 좌석이 이미 예약된 것으로 판명되면 Salvo가 즉시 INCR로 다음 좌석을 받아 다시 시도하고, 이것을 연속해서 수행하여 성공하거나 좌석이 없을 때까지 반복하는 것입니다. 이렇게 하면 사용자는 한 번 요청으로 빈 좌석을 자동으로 배정받을 수도 있지만, 동시에 여러 사용자가 있을 때 조금 불공평해질 가능성이 있고, 또 언제 반복을 멈출지(몇 번 시도할지) 결정하는 문제가 있습니다. 단순성을 위해 본 시스템에서는 한 요청에 한 좌석만 시도하도록 유지하는 편이 일관적입니다.
	•	좌석 번호에서 좌석명으로: 현재 좌석을 단순히 1~9 번호로 취급하지만, 실제 공연장에서는 “A열 1번”, “A열 2번” 혹은 “1층 5열” 등 좌석명/구역 체계가 있을 것입니다. 추후 좌석에 이름(레이블)을 부여하려면 seats 테이블에 좌석명을 나타내는 컬럼을 추가할 수 있습니다 (name 혹은 label 등). 이를 미리 고려한다면 좌석의 식별자는 그대로 숫자를 쓰되, 사용자 응답이나 출력에는 좌석명을 함께 제공하면 됩니다. 예컨대 seats 테이블에 name 컬럼을 추가하고 값으로 “A1”, “A2” 등을 넣어두면, 조회 API에서 { "id": 1, "name": "A1", "status": true } 식으로 전달 가능할 것입니다. 내부 로직은 번호에 의존해도 무방하지만, 만약 특정 좌석을 건너뛰거나 하는 요구사항이 생기면 Redis에서 단순 increment가 아닌 다른 방식(예: 남은 좌석 목록에서 하나 추첨?)도 필요할 수 있습니다. 현 단계에선 선착순 번호 부여가 핵심이므로, 좌석명은 부가적인 표시로 처리합니다.
	•	보안 및 무결성:
	•	인증: X-User-Id 헤더로 사용자 식별을 받고 있지만, 이것이 신뢰할 수 있는 값인지 검증이 필요합니다. 실제 서비스라면 사용자의 로그인 세션이나 JWT 토큰 등으로부터 추출된 사용자 ID를 백엔드까지 전달하거나, OpenResty 단계에서 인증 모듈을 통해 유효한 사용자만 이 API를 호출할 수 있게 해야 합니다. 현재 명세에는 인증 부분이 생략돼 있지만, 추후 OAuth2나 세션 관리 등을 엮어 실제 사용자 식별을 안전하게 해야 합니다.
	•	데이터 일관성: 좌석 예약 완료 후엔 다른 시스템(예: 결제 시스템)과 연계하거나, 혹은 시간 제한을 두고 결제가 완료되지 않으면 예약을 취소하는 등의 로직이 추가될 수 있습니다. 그런 경우 status=true로 바뀐 좌석을 다시 false로 돌리는 처리, 또는 reserved_by 필드를 NULL로 초기화하는 작업 등이 필요합니다. 이러한 예약 취소/만료 기능을 고려해 테이블에 reserved_at 타임스탬프를 넣어두거나 별도 reservations 테이블로 분리하여 관리하는 방안도 확장 아이디어입니다.
	•	로그 및 감사: 누가 언제 어떤 좌석을 예약했는지에 대한 기록을 남겨두는 것이 좋습니다. 현재 구조에서는 seats 테이블에 마지막 예약자만 남기게 되므로, 감사 로그용으로는 부족합니다. 따라서 reservations_history 같은 로그 테이블을 만들어 INSERT 해 놓거나, 애플리케이션 레벨에서 예약 성공/실패 내역을 별도로 저장하면 추후 문제 발생 시 분석이 가능합니다.
	•	성능 모니터링 및 튜닝:
	•	Redis의 부하를 모니터링하여 Lua 스크립트 실행이나 INCR 호출에 지연이 없는지 확인해야 합니다. Redis는 CPU 바운드이므로, 필요하다면 보다 성능이 좋은 서버나 클러스터로 이전 고려.
	•	PostgreSQL도 좌석 테이블에 동시 업데이트가 발생할 때 락 경합을 모니터링해야 합니다. 현재 9개 좌석 수준에선 문제가 없지만, 좌석 수가 늘고 동시에 수많은 예약이 들어오면 seats 테이블의 각 행이 동시에 갱신될 수 있습니다. 다행히 행 단위 잠금이므로 다른 좌석끼리는 서로 영향이 없습니다. 그러나 같은 좌석에 대한 중복 갱신 시도는 결국 한쪽이 실패하므로, 애플리케이션에서 이를 잘 처리하면 됩니다. 인덱스는 PK로 이미 잡혀있으므로 조회나 업데이트에 큰 지장은 없습니다. 그래도 트래픽이 매우 크다면 읽기 전용 쿼리(예: /api/v1/seats)는 캐시나 리플리카 DB를 활용하고, 쓰기는 마스터 DB에만 하도록 구조를 확장하는 방안도 있습니다.
	•	사용자 경험(UX) 개선: 기술 명세와 약간 거리가 있지만, 시스템 측면에서 예약 대기가 길어질 경우 클라이언트에 **대기열(Queue)**을 안내하거나, 실시간 좌석 변화를 웹소켓 등을 통해 통보하는 기능도 고려할 수 있습니다. 예를 들어 특정 사용자가 좌석을 예약하면 /api/v1/seats 데이터를 모든 사용자에게 푸시 알림하여 UI에 즉각 반영한다면 더 좋은 UX를 줄 수 있습니다. 이런 실시간 기능 추가는 현재 구조와 충돌나지 않으며, Salvo에서 좌석 상태 변경 시 Pub/Sub이나 WebSocket 메시지를 발송하도록 확장하면 됩니다. 단, 이러한 기능은 시스템 복잡도를 높이므로 트래픽 상황에 따라 선택적으로 도입하면 됩니다.
	•	테스트와 검증: 마지막으로, 확장에 앞서 현재 시스템이 제대로 동작하는지 충분한 부하 테스트와 케이스 검증이 필요합니다. 예를 들어 9명이 동시에 9석을 요청하는 시나리오, 10명이 9석을 쟁탈하는 시나리오, 동일 사용자가 연속해서 요청하는 시나리오 등을 만들어 중복 차단과 선착순 부여가 의도대로 되는지 확인해야 합니다. Redis Lua 스크립트의 원자성 덕분에 한 좌석에 두 명이 배정되는 일은 없겠지만 ￼, 테스트를 통해 이를 증명하는 것이 중요합니다. 또한 에러 상황 (Redis 다운, DB 다운 등)에서도 시스템이 어떻게 반응하는지 정의하고 대비책(Graceful degrade)을 마련해두면 안정적인 확장이 가능합니다.

以上과 같이, 본 공연 예약 시스템의 백엔드 구조는 모듈별로 역할이 분리되어 있어 확장이 용이합니다. OpenResty를 앞단에 둠으로써 트래픽 제어와 경량 필터링을 담당하고, Redis를 활용하여 전역 상태 관리(중복 요청 및 시퀀스 발급)를 처리하며, Salvo + PostgreSQL 조합으로 핵심 비즈니스 로직과 영속 데이터 관리를 수행합니다. 이러한 구조는 실제 대규모 트래픽의 티켓팅 시스템에서도 사용되는 패턴으로, 신뢰성과 성능을 모두 고려한 것입니다. 추후 요구사항 변경에도 각 계층을 튜닝하거나 교체함으로써 대응할 수 있으며, 모니터링과 지속적인 개선을 통해 원활한 공연 예약 서비스 운영이 가능할 것입니다.
</PRD>